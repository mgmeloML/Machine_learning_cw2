{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import models, transforms\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python Projects\\Machine_learning_cw2\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Python Projects\\Machine_learning_cw2\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path = 'model\\simclr_cifar-10.pth'\n",
    "checkpoint = torch.load(model_path, map_location=torch.device(device))\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.load_state_dict(checkpoint, strict=False)\n",
    "model.to(device)\n",
    "model.fc = nn.Identity() \n",
    "feature_extractor = model\n",
    "feature_extractor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transformations (resizing to 32x32 for CIFAR-10)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize to CIFAR-10 dimensions\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])  # Normalize with CIFAR-10 stats\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "cifar_dataset = CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
    "# Create a DataLoader for batch processing\n",
    "data_loader = DataLoader(cifar_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings():\n",
    "    # Store embeddings and labels\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Disable gradient computation for efficiency\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Pass images through feature extractor\n",
    "            features = feature_extractor(images)  # Output shape: (batch, 512, 1, 1)\n",
    "            \n",
    "            # Flatten feature maps (remove extra dimensions)\n",
    "            features = features.view(features.size(0), -1)  # (batch, 512)\n",
    "\n",
    "            # L2 Normalize the embeddings\n",
    "            features = torch.nn.functional.normalize(features, p=2, dim=1)\n",
    "\n",
    "            # Store results\n",
    "            all_embeddings.append(features.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    return all_embeddings, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typiclust(embeddings, labelled_examples = None, B = 10):\n",
    "    max_clusters = 500\n",
    "    K_neighbors = 20  # Number of neighbors to consider for density estimation\n",
    "    \n",
    "    if labelled_examples is not None:\n",
    "        selected_examples = labelled_examples\n",
    "    else:\n",
    "        selected_examples = []\n",
    "    \n",
    "    cumulative_budget = len(selected_examples) + B\n",
    "    K = min(cumulative_budget, max_clusters)\n",
    "\n",
    "    # Perform clustering using MiniBatchKMeans for efficiency\n",
    "    if K <= 50:\n",
    "        kmeans = KMeans(n_clusters=K, random_state=42)\n",
    "    else:\n",
    "        kmeans = MiniBatchKMeans(n_clusters=K, batch_size=256, random_state=42)\n",
    "\n",
    "    cluster_assignments = kmeans.fit_predict(embeddings)\n",
    "\n",
    "    # Identify uncovered clusters and their sizes\n",
    "    uncovered_clusters = []\n",
    "    for cluster_id in range(K):\n",
    "        cluster_indices = np.where(cluster_assignments == cluster_id)[0]\n",
    "        \n",
    "        # Check if the cluster is uncovered (no overlap with selected examples)\n",
    "        if set(cluster_indices) & set(selected_examples):\n",
    "            continue\n",
    "        \n",
    "        # Skip clusters with fewer than 5 samples\n",
    "        if len(cluster_indices) < 5:\n",
    "            continue\n",
    "        \n",
    "        uncovered_clusters.append((cluster_id, len(cluster_indices)))\n",
    "    \n",
    "    # Sort uncovered clusters by size in descending order\n",
    "    uncovered_clusters.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Select the B largest uncovered clusters\n",
    "    top_B_clusters = [cluster_id for cluster_id, _ in uncovered_clusters[:B]]\n",
    "\n",
    "    # Select the most typical example from each of the top B clusters\n",
    "    for cluster_id in top_B_clusters:\n",
    "        cluster_indices = np.where(cluster_assignments == cluster_id)[0]\n",
    "        cluster_embeddings = embeddings[cluster_indices]\n",
    "\n",
    "        # Compute pairwise distances using NearestNeighbors\n",
    "        nbrs = NearestNeighbors(n_neighbors=min(K_neighbors, len(cluster_embeddings))).fit(cluster_embeddings)\n",
    "        distances, _ = nbrs.kneighbors(cluster_embeddings)\n",
    "\n",
    "        # Compute typicality as the inverse of average distance to neighbors\n",
    "        avg_distances = distances.mean(axis=1)\n",
    "        typicality_scores = 1 / avg_distances\n",
    "\n",
    "        # Select the most typical example in the cluster\n",
    "        most_typical_idx = cluster_indices[typicality_scores.argmax()]\n",
    "        selected_examples.append(most_typical_idx)\n",
    "\n",
    "    \n",
    "    return selected_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typiclust_adaptive_typicality(embeddings, labelled_examples=None, B=10):\n",
    "    \n",
    "    max_clusters = 500\n",
    "    K_neighbors = 20  # Number of neighbors to consider for density estimation\n",
    "    \n",
    "    if labelled_examples is not None:\n",
    "        selected_examples = labelled_examples.copy()\n",
    "    else:\n",
    "        selected_examples = []\n",
    "    \n",
    "    cumulative_budget = len(selected_examples) + B\n",
    "    K = min(cumulative_budget, max_clusters)\n",
    "\n",
    "    # Perform clustering using MiniBatchKMeans for efficiency\n",
    "    if K <= 50:\n",
    "        kmeans = KMeans(n_clusters=K, random_state=42)\n",
    "    else:\n",
    "        kmeans = MiniBatchKMeans(n_clusters=K, batch_size=256, random_state=42)\n",
    "\n",
    "    cluster_assignments = kmeans.fit_predict(embeddings)\n",
    "\n",
    "    # Calculate adaptive threshold based on cluster size distribution\n",
    "    cluster_sizes = [len(np.where(cluster_assignments == c)[0]) for c in range(K)]\n",
    "    adaptive_threshold = max(5, np.percentile(cluster_sizes, 20))  # 20th percentile with min of 5\n",
    "\n",
    "    # Identify uncovered clusters and their sizes\n",
    "    uncovered_clusters = []\n",
    "    for cluster_id in range(K):\n",
    "        cluster_indices = np.where(cluster_assignments == cluster_id)[0]\n",
    "        \n",
    "        # Check if the cluster is uncovered (no overlap with selected examples)\n",
    "        if set(cluster_indices) & set(selected_examples):\n",
    "            continue\n",
    "        \n",
    "        # Skip clusters with fewer samples than adaptive threshold\n",
    "        if len(cluster_indices) < adaptive_threshold:\n",
    "            continue\n",
    "        \n",
    "        uncovered_clusters.append((cluster_id, len(cluster_indices)))\n",
    "    \n",
    "    # Sort uncovered clusters by size in descending order\n",
    "    uncovered_clusters.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Select the B largest uncovered clusters\n",
    "    top_B_clusters = [cluster_id for cluster_id, _ in uncovered_clusters[:B]]\n",
    "\n",
    "    # Select the most typical example from each of the top B clusters\n",
    "    for cluster_id in top_B_clusters:\n",
    "        cluster_indices = np.where(cluster_assignments == cluster_id)[0]\n",
    "        cluster_embeddings = embeddings[cluster_indices]\n",
    "\n",
    "        # Compute pairwise distances using NearestNeighbors\n",
    "        n_neighbors = min(K_neighbors, len(cluster_embeddings))\n",
    "        if n_neighbors < 2:  # Need at least 2 points for meaningful distances\n",
    "            continue\n",
    "            \n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors).fit(cluster_embeddings)\n",
    "        distances, _ = nbrs.kneighbors(cluster_embeddings)\n",
    "\n",
    "        # Compute typicality as the inverse of average distance to neighbors\n",
    "        avg_distances = distances.mean(axis=1)\n",
    "        typicality_scores = 1 / (avg_distances + 1e-8)  # Add small epsilon to avoid division by zero\n",
    "\n",
    "        # Select the most typical example in the cluster\n",
    "        most_typical_idx = cluster_indices[typicality_scores.argmax()]\n",
    "        selected_examples.append(most_typical_idx)\n",
    "\n",
    "    return selected_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_selection(embeddings, labelled_examples = None, B = 10):\n",
    "\n",
    "    \n",
    "    if labelled_examples is not None:\n",
    "        selected_examples = labelled_examples\n",
    "    else:\n",
    "        selected_examples = []\n",
    "\n",
    "    ublabelled_points = list(range(len(embeddings)))\n",
    "    ublabelled_points = [x for x in ublabelled_points if x not in selected_examples]\n",
    "\n",
    "    # Randomly select `budget` indices without replacement\n",
    "    selected_indices = np.random.choice(ublabelled_points, size=B, replace=False)\n",
    "    \n",
    "    selected_examples.extend(selected_indices)\n",
    "    \n",
    "    return selected_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformSubset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A custom wrapper to apply transformations to a subset of a dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "def fully_supervised_evaluation(selected_indices, device, epochs=100):\n",
    "    # Define transformations for training (including augmentation)\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
    "    ])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
    "    ])\n",
    "\n",
    "    # Load CIFAR-10 dataset\n",
    "    cifar_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=None, download=True)\n",
    "    test_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=test_transform, download=True)\n",
    "\n",
    "    # Create a subset of CIFAR-10 with selected examples\n",
    "    selected_subset = Subset(cifar_dataset, selected_indices)\n",
    "\n",
    "    # Apply transformations only to the subset\n",
    "    train_dataset = TransformSubset(selected_subset, transform=train_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    # Initialize model\n",
    "    model = models.resnet18(num_classes=10).to(device)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.025, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "    # Training function\n",
    "    def train():\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Testing function\n",
    "    def test():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        return accuracy\n",
    "    \n",
    "    # Training loop\n",
    "    best_accuracy = 0.0\n",
    "    for epoch in range(epochs):  # Increased epochs as per modifications\n",
    "        train()\n",
    "        scheduler.step()\n",
    "        if (epoch + 1) % 10 == 0:  # Test every 10 epochs\n",
    "            accuracy = test()\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "    \n",
    "    return best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully Supervised with Linear Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_supervised_with_self_supervised_embeddings_evaluation(all_embeddings, all_labels, selected_indices, feature_extractor, device, batch_size=128, epochs=200):\n",
    "    # Create train dataset with selected examples\n",
    "    train_embeddings = all_embeddings[selected_indices]\n",
    "    train_labels = all_labels[selected_indices]\n",
    "\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(train_embeddings),\n",
    "        torch.tensor(train_labels)\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Load test dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
    "    ])\n",
    "    test_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "    # Extract test embeddings using the feature extractor\n",
    "    test_embeddings = []\n",
    "    test_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in DataLoader(test_dataset, batch_size=batch_size, shuffle=False):\n",
    "            images = images.to(device)\n",
    "            features = feature_extractor(images)\n",
    "            features = features.view(features.size(0), -1)\n",
    "            features = torch.nn.functional.normalize(features, p=2, dim=1)\n",
    "            test_embeddings.append(features.cpu().numpy())\n",
    "            test_labels.append(labels.numpy())\n",
    "\n",
    "    test_embeddings = np.vstack(test_embeddings)\n",
    "    test_labels = np.concatenate(test_labels)\n",
    "\n",
    "    test_dataset = TensorDataset(\n",
    "        torch.tensor(test_embeddings),\n",
    "        torch.tensor(test_labels)\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Define linear classifier\n",
    "    input_dim = train_embeddings.shape[1]  # Should be 512 if using ResNet18\n",
    "    num_classes = 10  # For CIFAR-10\n",
    "    classifier = nn.Linear(input_dim, num_classes).to(device)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.SGD(classifier.parameters(), lr=2.5, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training function\n",
    "    def train():\n",
    "        classifier.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = classifier(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "    # Testing function\n",
    "    def test():\n",
    "        classifier.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = classifier(data)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        return accuracy\n",
    "\n",
    "    # Training loop\n",
    "    best_accuracy = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        train()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            accuracy = test()\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "\n",
    "    # Final evaluation\n",
    "    print(f\"Best Test Accuracy: {best_accuracy:.2f}%\")\n",
    "    return best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semi - Supervised with FlexMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define WideResNet architecture (unchanged)\n",
    "class WideBasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(WideBasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, \n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, \n",
    "                          stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(x))\n",
    "        out = self.conv1(out)\n",
    "        out = torch.relu(self.bn2(out))\n",
    "        out = self.conv2(out)\n",
    "        out += self.shortcut(x)\n",
    "        return out\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth, widen_factor, num_classes):\n",
    "        super(WideResNet, self).__init__()\n",
    "        n_channels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
    "        assert (depth - 4) % 6 == 0, 'depth should be 6n+4'\n",
    "        n = (depth - 4) // 6\n",
    "        self.conv1 = nn.Conv2d(3, n_channels[0], kernel_size=3, \n",
    "                               padding=1, bias=False)\n",
    "        self.layer1 = self._make_layer(n, n_channels[0], n_channels[1], 1)\n",
    "        self.layer2 = self._make_layer(n, n_channels[1], n_channels[2], 2)\n",
    "        self.layer3 = self._make_layer(n, n_channels[2], n_channels[3], 2)\n",
    "        self.bn1 = nn.BatchNorm2d(n_channels[3])\n",
    "        self.fc = nn.Linear(n_channels[3], num_classes)\n",
    "\n",
    "    def _make_layer(self, n, in_channels, out_channels, stride):\n",
    "        layers = [WideBasicBlock(in_channels, out_channels, stride)]\n",
    "        for _ in range(1, n):\n",
    "            layers.append(WideBasicBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = torch.relu(self.bn1(out))\n",
    "        out = torch.mean(out, dim=(2, 3))  # Global average pooling\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Semi-Supervised Evaluation Function\n",
    "def semi_supervised_evaluation(selected_indices, device, epochs=400, batch_size=64, lr=0.03, weight_decay=0.0005, momentum=0.9, threshold=0.95):\n",
    "    # Define transformations\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
    "    ])\n",
    "\n",
    "    # Load CIFAR-10 dataset\n",
    "    train_dataset = CIFAR10(root=\"./data\", train=True, transform=transform_train, download=True)\n",
    "    test_dataset = CIFAR10(root=\"./data\", train=False, transform=transform_test, download=True)\n",
    "\n",
    "    # Create labeled and unlabeled subsets\n",
    "    labeled_subset = Subset(train_dataset, selected_indices)\n",
    "    unlabeled_subset = Subset(train_dataset, list(set(range(len(train_dataset))) - set(selected_indices)))\n",
    "\n",
    "    labeled_loader = DataLoader(labeled_subset, batch_size=batch_size, shuffle=True)\n",
    "    unlabeled_loader = DataLoader(unlabeled_subset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    # Initialize WideResNet-28-2\n",
    "    model = WideResNet(depth=28, widen_factor=2, num_classes=10).to(device)\n",
    "\n",
    "    # Define optimizer and scheduler\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay, nesterov=True)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training function with FlexMatch\n",
    "    def train(unlabeled_loader_iter):\n",
    "        model.train()\n",
    "        for batch_idx, (labeled_data, labeled_target) in enumerate(labeled_loader):\n",
    "            # Get labeled data\n",
    "            labeled_data, labeled_target = labeled_data.to(device), labeled_target.to(device)\n",
    "\n",
    "            # Get unlabeled data\n",
    "            try:\n",
    "                unlabeled_data, _ = next(unlabeled_loader_iter)\n",
    "            except StopIteration:\n",
    "                unlabeled_loader_iter = iter(unlabeled_loader)\n",
    "                unlabeled_data, _ = next(unlabeled_loader_iter)\n",
    "            unlabeled_data = unlabeled_data.to(device)\n",
    "\n",
    "            # Forward pass for labeled data\n",
    "            labeled_output = model(labeled_data)\n",
    "            supervised_loss = criterion(labeled_output, labeled_target)\n",
    "\n",
    "            # Forward pass for unlabeled data (pseudo-labeling)\n",
    "            unlabeled_output = model(unlabeled_data)\n",
    "            pseudo_labels = torch.argmax(unlabeled_output, dim=1)\n",
    "            confidence = torch.max(torch.softmax(unlabeled_output, dim=1), dim=1).values\n",
    "\n",
    "            # Apply confidence threshold for pseudo-labels\n",
    "            mask = confidence > threshold\n",
    "            if mask.sum() > 0:\n",
    "                unsupervised_loss = criterion(unlabeled_output[mask], pseudo_labels[mask])\n",
    "            else:\n",
    "                unsupervised_loss = 0.0\n",
    "\n",
    "            # Combine losses\n",
    "            loss = supervised_loss + unsupervised_loss\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Testing function\n",
    "    def test():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "        return accuracy\n",
    "\n",
    "    # Training loop\n",
    "    unlabeled_loader_iter = iter(unlabeled_loader)\n",
    "    best_accuracy = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        train(unlabeled_loader_iter)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            accuracy = test()\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "\n",
    "    # Final evaluation\n",
    "    final_accuracy = test()\n",
    "    return final_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(tpc_acc, rand_acc, title):\n",
    "    \"\"\"\n",
    "    Plots accuracy curves for TypiClust and Random Selection with shaded standard error regions.\n",
    "\n",
    "    Parameters:\n",
    "    - tpc_acc: List of lists (or NumPy array) containing accuracy values across multiple trials for TypiClust.\n",
    "    - rand_acc: List of lists (or NumPy array) containing accuracy values across multiple trials for Random Selection.\n",
    "    \"\"\"\n",
    "    cumulative_budget = [10, 20, 30, 40, 50, 60]\n",
    "\n",
    "    # Convert lists to NumPy arrays for easier computation\n",
    "    tpc_acc = np.array(tpc_acc).T\n",
    "    rand_acc = np.array(rand_acc).T\n",
    "\n",
    "    # Compute mean and standard error\n",
    "    tpc_mean = np.mean(tpc_acc, axis=0)\n",
    "    tpc_std = np.std(tpc_acc, axis=0, ddof=1) / np.sqrt(tpc_acc.shape[0])\n",
    "\n",
    "    rand_mean = np.mean(rand_acc, axis=0)\n",
    "    rand_std = np.std(rand_acc, axis=0, ddof=1) / np.sqrt(rand_acc.shape[0])\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # TPC line plot with shaded standard error\n",
    "    plt.plot(cumulative_budget, tpc_mean, marker='o', linestyle='-', color='blue', label=\"TypiClust\")\n",
    "    plt.fill_between(cumulative_budget, tpc_mean - tpc_std, tpc_mean + tpc_std, color='blue', alpha=0.2)\n",
    "\n",
    "    # Random selection line plot with shaded standard error\n",
    "    plt.plot(cumulative_budget, rand_mean, marker='o', linestyle='-', color='red', label=\"Random Selection\")\n",
    "    plt.fill_between(cumulative_budget, rand_mean - rand_std, rand_mean + rand_std, color='red', alpha=0.2)\n",
    "\n",
    "    # Labels and legend\n",
    "    plt.xlabel(\"Cumulative Budget\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_chart(tpc_acc, rand_acc, title):\n",
    "    \"\"\"\n",
    "    Plots a bar chart comparing TypiClust and Random Selection accuracy across multiple runs.\n",
    "\n",
    "    Parameters:\n",
    "    - tpc_acc: List of accuracy values for TypiClust across multiple runs.\n",
    "    - rand_acc: List of accuracy values for Random Selection across multiple runs.\n",
    "    - title: (str) Title of the plot.\n",
    "    \"\"\"\n",
    "    # Compute mean and standard deviation\n",
    "    tpc_mean = np.mean(tpc_acc)\n",
    "    tpc_std = np.std(tpc_acc, ddof=1)  # ddof=1 for sample standard deviation\n",
    "\n",
    "    rand_mean = np.mean(rand_acc)\n",
    "    rand_std = np.std(rand_acc, ddof=1)\n",
    "\n",
    "    methods = [\"Random\", \"TypiClust\"]\n",
    "    accuracies = [rand_mean, tpc_mean]\n",
    "    errors = [rand_std, tpc_std]\n",
    "\n",
    "    colors = [\"black\", \"blue\"]\n",
    "\n",
    "    plt.figure(figsize=(4, 5))\n",
    "    bars = plt.bar(methods, accuracies, yerr=errors, capsize=5, color=colors, alpha=0.8)\n",
    "\n",
    "    # Annotate values on top of bars\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, f\"{acc:.1f}\", \n",
    "                 ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "    plt.ylim(0, 100)\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(title)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings, all_labels = extract_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m tpc_indices \u001b[38;5;241m=\u001b[39m typiclust(all_embeddings)\n\u001b[0;32m      7\u001b[0m rand_indices \u001b[38;5;241m=\u001b[39m random_selection(all_embeddings)\n\u001b[1;32m----> 9\u001b[0m tpc_acc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfully_supervised_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtpc_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     10\u001b[0m rand_acc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(fully_supervised_evaluation(rand_indices, device))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Active Learning Iterations\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[51], line 88\u001b[0m, in \u001b[0;36mfully_supervised_evaluation\u001b[1;34m(selected_indices, device, epochs)\u001b[0m\n\u001b[0;32m     86\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Test every 10 epochs\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accuracy \u001b[38;5;241m>\u001b[39m best_accuracy:\n\u001b[0;32m     90\u001b[0m         best_accuracy \u001b[38;5;241m=\u001b[39m accuracy\n",
      "Cell \u001b[1;32mIn[51], line 72\u001b[0m, in \u001b[0;36mfully_supervised_evaluation.<locals>.test\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m     73\u001b[0m         inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     74\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "File \u001b[1;32md:\\Python Projects\\Machine_learning_cw2\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32md:\\Python Projects\\Machine_learning_cw2\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Python Projects\\Machine_learning_cw2\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Python Projects\\Machine_learning_cw2\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Python Projects\\Machine_learning_cw2\\.venv\\lib\\site-packages\\torchvision\\datasets\\cifar.py:119\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    116\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32md:\\Python Projects\\Machine_learning_cw2\\.venv\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32md:\\Python Projects\\Machine_learning_cw2\\.venv\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python Projects\\Machine_learning_cw2\\.venv\\lib\\site-packages\\torchvision\\transforms\\functional.py:174\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    172\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mview(pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m], pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m], F_pil\u001b[38;5;241m.\u001b[39mget_image_num_channels(pic))\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mdefault_float_dtype)\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tpc_acc = [[] for _ in range(6)]\n",
    "rand_acc = [[] for _ in range(6)]\n",
    "\n",
    "for _ in range(1):\n",
    "    # Initial Pool\n",
    "    tpc_indices = typiclust(all_embeddings)\n",
    "    rand_indices = random_selection(all_embeddings)\n",
    "\n",
    "    tpc_acc[0].append(fully_supervised_evaluation(tpc_indices, device))\n",
    "    rand_acc[0].append(fully_supervised_evaluation(rand_indices, device))\n",
    "\n",
    "    # Active Learning Iterations\n",
    "    for i in range(1, 6):\n",
    "        tpc_indices = typiclust(all_embeddings, tpc_indices)\n",
    "        rand_indices = random_selection(all_embeddings, rand_indices)\n",
    "\n",
    "        tpc_acc[i].append(fully_supervised_evaluation(tpc_indices, device))\n",
    "        rand_acc[i].append(fully_supervised_evaluation(rand_indices, device))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpc_acc = np.array(tpc_acc)\n",
    "rand_acc = np.array(rand_acc)\n",
    "# Perform Wilcoxon signed-rank test\n",
    "t_stat, p_value = ttest_rel(tpc_acc.flatten(), rand_acc.flatten())\n",
    "\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(tpc_acc, rand_acc, \"FULLY SUPERVISED FRAMEWORK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpc_acc = [[] for _ in range(6)]\n",
    "rand_acc = [[] for _ in range(6)]\n",
    "\n",
    "for _ in range(1):\n",
    "    # Initial Pool\n",
    "    tpc_indices = typiclust(all_embeddings)\n",
    "    rand_indices = random_selection(all_embeddings)\n",
    "\n",
    "    tpc_acc[0].append(fully_supervised_with_self_supervised_embeddings_evaluation(all_embeddings, all_labels, tpc_indices, feature_extractor, device))\n",
    "    rand_acc[0].append(fully_supervised_with_self_supervised_embeddings_evaluation(all_embeddings, all_labels, rand_indices, feature_extractor, device))\n",
    "\n",
    "    # Active Learning Iterations\n",
    "    for i in range(1, 6):\n",
    "        tpc_indices = typiclust(all_embeddings, tpc_indices)\n",
    "        rand_indices = random_selection(all_embeddings, rand_indices)\n",
    "\n",
    "        tpc_acc[i].append(fully_supervised_with_self_supervised_embeddings_evaluation(all_embeddings, all_labels, tpc_indices, feature_extractor, device))\n",
    "        rand_acc[i].append(fully_supervised_with_self_supervised_embeddings_evaluation(all_embeddings, all_labels, rand_indices, feature_extractor, device))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpc_acc = np.array(tpc_acc)\n",
    "rand_acc = np.array(rand_acc)\n",
    "# Perform Wilcoxon signed-rank test\n",
    "t_stat, p_value = ttest_rel(tpc_acc.flatten(), rand_acc.flatten())\n",
    "\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(tpc_acc, rand_acc, title=\"FULLY SUPERVISED WITH SELF-SUPERVISED EMBEDDING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpc_acc = []\n",
    "rand_acc = []\n",
    "\n",
    "for _ in range(1):\n",
    "    tpc_indices = typiclust(all_embeddings)\n",
    "    rand_indices = random_selection(all_embeddings)\n",
    "\n",
    "    tpc_acc.append(semi_supervised_evaluation(tpc_indices, device))\n",
    "    rand_acc.append(semi_supervised_evaluation(rand_indices, device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_chart(tpc_acc, rand_acc, title=\"SEMI-SUPERVISED FRAMEWORK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpc_acc = [[] for _ in range(6)]\n",
    "tpc_mod_acc = [[] for _ in range(6)]\n",
    "\n",
    "for _ in range(1):\n",
    "    # Initial Pool\n",
    "    tpc_indices = typiclust(all_embeddings)\n",
    "    tpc_mod_indices = typiclust_adaptive_typicality(all_embeddings)\n",
    "\n",
    "    tpc_acc[0].append(fully_supervised_evaluation(tpc_indices, device))\n",
    "    tpc_mod_acc[0].append(fully_supervised_evaluation(tpc_mod_indices, device))\n",
    "\n",
    "    # Active Learning Iterations\n",
    "    for i in range(1, 6):\n",
    "        tpc_indices = typiclust(all_embeddings, tpc_indices)\n",
    "        tpc_mod_indices = random_selection(all_embeddings, tpc_mod_indices)\n",
    "\n",
    "        tpc_acc[i].append(fully_supervised_evaluation(tpc_indices, device))\n",
    "        tpc_mod_acc[i].append(fully_supervised_evaluation(tpc_mod_indices, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(tpc_acc, rand_acc, title):\n",
    "    \"\"\"\n",
    "    Plots accuracy curves for TypiClust and Random Selection with shaded standard error regions.\n",
    "\n",
    "    Parameters:\n",
    "    - tpc_acc: List of lists (or NumPy array) containing accuracy values across multiple trials for TypiClust.\n",
    "    - rand_acc: List of lists (or NumPy array) containing accuracy values across multiple trials for Random Selection.\n",
    "    \"\"\"\n",
    "    cumulative_budget = [10, 20, 30, 40, 50, 60]\n",
    "\n",
    "    # Convert lists to NumPy arrays for easier computation\n",
    "    tpc_acc = np.array(tpc_acc).T\n",
    "    rand_acc = np.array(rand_acc).T\n",
    "\n",
    "    # Compute mean and standard error\n",
    "    tpc_mean = np.mean(tpc_acc, axis=0)\n",
    "    tpc_std = np.std(tpc_acc, axis=0, ddof=1) / np.sqrt(tpc_acc.shape[0])\n",
    "\n",
    "    rand_mean = np.mean(rand_acc, axis=0)\n",
    "    rand_std = np.std(rand_acc, axis=0, ddof=1) / np.sqrt(rand_acc.shape[0])\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # TPC line plot with shaded standard error\n",
    "    plt.plot(cumulative_budget, tpc_mean, marker='o', linestyle='-', color='blue', label=\"TypiClust\")\n",
    "    plt.fill_between(cumulative_budget, tpc_mean - tpc_std, tpc_mean + tpc_std, color='blue', alpha=0.2)\n",
    "\n",
    "    # Random selection line plot with shaded standard error\n",
    "    plt.plot(cumulative_budget, rand_mean, marker='o', linestyle='-', color='red', label=\"TypiClust Modified\")\n",
    "    plt.fill_between(cumulative_budget, rand_mean - rand_std, rand_mean + rand_std, color='red', alpha=0.2)\n",
    "\n",
    "    # Labels and legend\n",
    "    plt.xlabel(\"Cumulative Budget\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(tpc_acc, tpc_mod_acc, \"Fully Supervised\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
